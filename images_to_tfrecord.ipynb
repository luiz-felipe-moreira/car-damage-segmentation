{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/luiz-felipe-moreira/car-damage-segmentation/blob/main/images_to_tfrecord.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SUUX9CnCYI9Y"
      },
      "source": [
        "# Instance Segmentation de Danos em Automóveis usando TF Model Garden"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UjP7bQUdTeFr"
      },
      "source": [
        "\n",
        "Este notebook faz o treinamento (fine-tuning) de uma [Mask R-CNN](https://arxiv.org/abs/1703.06870) implementada no [pacote TensorFlow Model Garden](https://pypi.org/project/tf-models-official/) (tensorflow-models). O backbone utilizado (checkpoint) também foi obtido do [Model Garden](https://www.tensorflow.org/tfmodels).  \n",
        "  \n",
        "Descrição do Model Garden:  \n",
        "\"[Model Garden](https://www.tensorflow.org/tfmodels) contains a collection of state-of-the-art models, implemented with TensorFlow's high-level APIs. The implementations demonstrate the best practices for modeling, letting users to take full advantage of TensorFlow for their research and product development.\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sP7yiEG9tU_y"
      },
      "source": [
        "##Verifica se estamos usando GPU e qual sua configuração"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "23TOba33L4qf",
        "outputId": "c35e520f-0cd9-412e-c291-d59b34ececad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sun Nov 26 16:26:55 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P0    25W / 300W |      0MiB / 16384MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bMxD7ZcPtE5H",
        "outputId": "69707fff-7c3e-41d8-acdb-d15fe3dd1451"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Your runtime has 54.8 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n"
          ]
        }
      ],
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RDp6Kk1Baoi4"
      },
      "source": [
        "## Instala as dependências"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tvfDt5aEsJ4x",
        "outputId": "9d97d36e-142f-4667-af0e-a8ea4b547a39"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Python 3.10.12\n"
          ]
        }
      ],
      "source": [
        "!python --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hcl98qUOxlL8",
        "outputId": "97c561b1-ce84-4960-d8cd-ed8496b933fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.4/106.4 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.2/241.2 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.7/61.7 MB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for remotezip (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q \"tf-models-official\"==2.14.2\n",
        "!pip install -U -q remotezip tqdm opencv-python einops"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5-gCe_YTapey"
      },
      "source": [
        "## Importa as bibliotecas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qa9552Ukgf3d"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import io\n",
        "import json\n",
        "import tqdm\n",
        "import shutil\n",
        "import pprint\n",
        "import pathlib\n",
        "import tempfile\n",
        "import requests\n",
        "import collections\n",
        "import matplotlib\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from PIL import Image\n",
        "from six import BytesIO\n",
        "from etils import epath\n",
        "from IPython import display\n",
        "from urllib.request import urlopen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tSCMIDRDP2fV",
        "outputId": "f564d216-e1ec-47f5-bd51-5bb1c7283f2a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.14.0\n"
          ]
        }
      ],
      "source": [
        "import orbit\n",
        "import tensorflow as tf\n",
        "import tensorflow_models as tfm\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "from official.core import exp_factory, base_trainer\n",
        "from official.core import config_definitions as cfg\n",
        "from official.vision.data import tfrecord_lib\n",
        "from official.vision.serving import export_saved_model_lib\n",
        "from official.vision.dataloaders.tf_example_decoder import TfExampleDecoder\n",
        "from official.vision.utils.object_detection import visualization_utils\n",
        "from official.vision.ops.preprocess_ops import normalize_image, resize_and_crop_image\n",
        "from official.vision.data.create_coco_tf_record import coco_annotations_to_lists\n",
        "\n",
        "pp = pprint.PrettyPrinter(indent=4) # Set Pretty Print Indentation\n",
        "print(tf.__version__) # Check the version of tensorflow used\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ms9KFxv26ne6"
      },
      "source": [
        "## Definição da quantidade de classes do dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JSzKCRg20ith"
      },
      "outputs": [],
      "source": [
        "NUM_CLASSES = 6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GIrXW8sp2bKa"
      },
      "source": [
        "## Download dataset e conversão para TFRecord\n",
        "Faz download do dataset (imagens do meu Google Drive e anotações do Cloud Storage) para a máquina usada pelo Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F_A9_cS310jf",
        "outputId": "980d8b70-0034-4b8c-bf1c-2a77fe118f11"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Copying gs://car-damage-recognition/instances_train2017.json...\n",
            "| [1 files][ 19.6 MiB/ 19.6 MiB]                                                \n",
            "Operation completed over 1 objects/19.6 MiB.                                     \n",
            "Copying gs://car-damage-recognition/instances_val2017.json...\n",
            "- [1 files][  5.7 MiB/  5.7 MiB]                                                \n",
            "Operation completed over 1 objects/5.7 MiB.                                      \n",
            "Copying gs://car-damage-recognition/instances_test2017.json...\n",
            "- [1 files][  2.5 MiB/  2.5 MiB]                                                \n",
            "Operation completed over 1 objects/2.5 MiB.                                      \n"
          ]
        }
      ],
      "source": [
        "# @title Download JSONs de anotação\n",
        "\n",
        "!gsutil cp gs://car-damage-recognition/instances_train2017.json .\n",
        "!gsutil cp gs://car-damage-recognition/instances_val2017.json .\n",
        "!gsutil cp gs://car-damage-recognition/instances_test2017.json ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kB-C5Svj11S0"
      },
      "outputs": [],
      "source": [
        "# @title Funções para parsing das anotações do dataset CarDD\n",
        "\n",
        "def get_category_map(annotation_path, num_classes):\n",
        "  with epath.Path(annotation_path).open() as f:\n",
        "      data = json.load(f)\n",
        "\n",
        "  category_map = {id+1: {'id': cat_dict['id'],\n",
        "                       'name': cat_dict['name']}\n",
        "                  for id, cat_dict in enumerate(data['categories'][:num_classes])}\n",
        "  return category_map\n",
        "\n",
        "class CarDDAnnotation:\n",
        "  \"\"\"CarDD annotation helper class.\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, annotation_path):\n",
        "    with epath.Path(annotation_path).open() as f:\n",
        "      data = json.load(f)\n",
        "    self._data = data\n",
        "\n",
        "    img_id2annotations = collections.defaultdict(list)\n",
        "    for a in self._data.get('annotations', []):\n",
        "      if a['category_id'] in category_ids:\n",
        "        img_id2annotations[a['image_id']].append(a)\n",
        "    self._img_id2annotations = {\n",
        "        k: list(sorted(v, key=lambda a: a['id']))\n",
        "        for k, v in img_id2annotations.items()\n",
        "    }\n",
        "\n",
        "  @property\n",
        "  def categories(self):\n",
        "    \"\"\"Return the category dicts, as sorted in the file.\"\"\"\n",
        "    return self._data['categories']\n",
        "\n",
        "  @property\n",
        "  def images(self):\n",
        "    \"\"\"Return the image dicts, as sorted in the file.\"\"\"\n",
        "    sub_images = []\n",
        "    for image_info in self._data['images']:\n",
        "      if image_info['id'] in self._img_id2annotations:\n",
        "        sub_images.append(image_info)\n",
        "    return sub_images\n",
        "\n",
        "  def get_annotations(self, img_id):\n",
        "    \"\"\"Return all annotations associated with the image id string.\"\"\"\n",
        "    # Some images don't have any annotations. Return empty list instead.\n",
        "    return self._img_id2annotations.get(img_id, [])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uD-3zybIwdBm",
        "outputId": "f2c4c14f-38e6-480f-b2c6-cdc90b3cc266"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{1: {'id': 1, 'name': 'dent'},\n",
              " 2: {'id': 2, 'name': 'scratch'},\n",
              " 3: {'id': 3, 'name': 'crack'},\n",
              " 4: {'id': 4, 'name': 'glass shatter'},\n",
              " 5: {'id': 5, 'name': 'lamp broken'},\n",
              " 6: {'id': 6, 'name': 'tire flat'}}"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# @title Obtenção das categorias\n",
        "train_annotation_path = './instances_train2017.json'\n",
        "valid_annotation_path = './instances_val2017.json'\n",
        "test_annotation_path = './instances_test2017.json'\n",
        "\n",
        "category_index = get_category_map(valid_annotation_path, NUM_CLASSES)\n",
        "category_ids = list(category_index.keys())\n",
        "category_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wqYbAZzC4Fa_",
        "outputId": "b93432d5-0a7b-4764-d746-aaa04d777633"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# @title Download das imagens do dataset, salvas no Google Drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "if not os.path.exists('./cardd_dataset/'):\n",
        "  os.mkdir('./cardd_dataset/')\n",
        "!cp -r /content/drive/My\\ Drive/instance_segmentation_data/CarDD_COCO/train2017 /content/cardd_dataset\n",
        "!cp -r /content/drive/My\\ Drive/instance_segmentation_data/CarDD_COCO/val2017 /content/cardd_dataset\n",
        "!cp -r /content/drive/My\\ Drive/instance_segmentation_data/CarDD_COCO/test2017 /content/cardd_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ohnUZGwfzCGl"
      },
      "source": [
        "##Geração dos TFRecords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jPAArTGcyxvm"
      },
      "outputs": [],
      "source": [
        "def _generate_tf_records(prefix, images_dir, annotation_file, output_dir, num_shards=8):\n",
        "    \"\"\"Generate TFRecords.\"\"\"\n",
        "\n",
        "    cardd_annotation = CarDDAnnotation(annotation_file)\n",
        "\n",
        "    def _process_example(prefix, image_info, id_to_name_map):\n",
        "      filename = image_info['file_name']\n",
        "\n",
        "      image = tf.io.read_file(os.path.join(images_dir, filename))\n",
        "      instances = cardd_annotation.get_annotations(img_id=image_info['id'])\n",
        "\n",
        "      data, _ = coco_annotations_to_lists(instances,\n",
        "                                          id_to_name_map,\n",
        "                                          image_info['height'],\n",
        "                                          image_info['width'],\n",
        "                                          include_masks=True)\n",
        "      keys_to_features = {\n",
        "          'image/encoded':\n",
        "              tfrecord_lib.convert_to_feature(image.numpy()),\n",
        "          'image/filename':\n",
        "               tfrecord_lib.convert_to_feature(filename.encode('utf8')),\n",
        "          'image/format':\n",
        "              tfrecord_lib.convert_to_feature('jpg'.encode('utf8')),\n",
        "          'image/height':\n",
        "              tfrecord_lib.convert_to_feature(image_info['height']),\n",
        "          'image/width':\n",
        "              tfrecord_lib.convert_to_feature(image_info['width']),\n",
        "          'image/source_id':\n",
        "              tfrecord_lib.convert_to_feature(str(image_info['id']).encode('utf8')),\n",
        "          'image/object/bbox/xmin':\n",
        "              tfrecord_lib.convert_to_feature(data['xmin']),\n",
        "          'image/object/bbox/xmax':\n",
        "              tfrecord_lib.convert_to_feature(data['xmax']),\n",
        "          'image/object/bbox/ymin':\n",
        "              tfrecord_lib.convert_to_feature(data['ymin']),\n",
        "          'image/object/bbox/ymax':\n",
        "              tfrecord_lib.convert_to_feature(data['ymax']),\n",
        "          'image/object/class/text':\n",
        "              tfrecord_lib.convert_to_feature(data['category_names']),\n",
        "          'image/object/class/label':\n",
        "              tfrecord_lib.convert_to_feature(data['category_id']),\n",
        "          'image/object/is_crowd':\n",
        "              tfrecord_lib.convert_to_feature(data['is_crowd']),\n",
        "          'image/object/area':\n",
        "              tfrecord_lib.convert_to_feature(data['area'], 'float_list'),\n",
        "          'image/object/mask':\n",
        "              tfrecord_lib.convert_to_feature(data['encoded_mask_png'])\n",
        "      }\n",
        "      example = tf.train.Example(\n",
        "          features=tf.train.Features(feature=keys_to_features))\n",
        "      return example\n",
        "\n",
        "    writers = [\n",
        "        tf.io.TFRecordWriter(\n",
        "            output_dir + prefix +'-%05d-of-%05d.tfrecord' % (i, num_shards))\n",
        "        for i in range(num_shards)\n",
        "    ]\n",
        "    id_to_name_map = {cat_dict['id']: cat_dict['name']\n",
        "                      for cat_dict in cardd_annotation.categories[:NUM_CLASSES]}\n",
        "    for idx, image_info in enumerate(tqdm.tqdm(cardd_annotation.images)):\n",
        "      tf_example = _process_example(prefix, image_info, id_to_name_map)\n",
        "      writers[idx % num_shards].write(tf_example.SerializeToString())\n",
        "\n",
        "    del cardd_annotation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8XQdqPcu0PME"
      },
      "outputs": [],
      "source": [
        "train_prefix = 'train'\n",
        "valid_prefix = 'val'\n",
        "test_prefix = 'test'\n",
        "\n",
        "TRAIN_IMGS_DIR = './cardd_dataset/train2017/'\n",
        "VALID_IMGS_DIR = './cardd_dataset/val2017/'\n",
        "TEST_IMGS_DIR = './cardd_dataset/test2017/'\n",
        "\n",
        "\n",
        "tf_records_dir = './cardd_tfrecords_all_sets/'\n",
        "if not os.path.exists(tf_records_dir):\n",
        "  os.mkdir(tf_records_dir)\n",
        "\n",
        "_generate_tf_records(train_prefix,\n",
        "                     TRAIN_IMGS_DIR,\n",
        "                     train_annotation_path,\n",
        "                     tf_records_dir,\n",
        "                     16)\n",
        "\n",
        "_generate_tf_records(valid_prefix,\n",
        "                     VALID_IMGS_DIR,\n",
        "                     valid_annotation_path,\n",
        "                     tf_records_dir,\n",
        "                     8)\n",
        "\n",
        "_generate_tf_records(test_prefix,\n",
        "                     TEST_IMGS_DIR,\n",
        "                     test_annotation_path,\n",
        "                     tf_records_dir,\n",
        "                     4)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Copia as pastas contendo os arquivos TFRecords de cada conjunto para um bucket do Google Cloud Storage. Os arquivos ficarão disponíveis no GCS no seguinte caminho:\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "*   Treino: gs://car-damage-recognition/cardd_tfrecords_all_sets/train\n",
        "*   Validação: gs://car-damage-recognition/cardd_tfrecords_all_sets/val\n",
        "*   Teste: gs://car-damage-recognition/cardd_tfrecords_all_sets/test"
      ],
      "metadata": {
        "id": "zqVTqWlWoHz6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Af5gO8Pj1bIN",
        "outputId": "57738f79-fa06-485d-9d86-7bc8dadc8c9b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Copying file://./cardd_tfrecords_all_sets/val-00001-of-00008.tfrecord [Content-Type=application/octet-stream]...\n",
            "Copying file://./cardd_tfrecords_all_sets/train-00013-of-00016.tfrecord [Content-Type=application/octet-stream]...\n",
            "Copying file://./cardd_tfrecords_all_sets/train-00006-of-00016.tfrecord [Content-Type=application/octet-stream]...\n",
            "Copying file://./cardd_tfrecords_all_sets/train-00014-of-00016.tfrecord [Content-Type=application/octet-stream]...\n",
            "\\ [4 files][459.5 MiB/459.5 MiB]   28.0 MiB/s                                   \n",
            "==> NOTE: You are performing a sequence of gsutil operations that may\n",
            "run significantly faster if you instead use gsutil -m cp ... Please\n",
            "see the -m section under \"gsutil help options\" for further information\n",
            "about when gsutil -m can be advantageous.\n",
            "\n",
            "Copying file://./cardd_tfrecords_all_sets/train-00005-of-00016.tfrecord [Content-Type=application/octet-stream]...\n",
            "Copying file://./cardd_tfrecords_all_sets/train-00003-of-00016.tfrecord [Content-Type=application/octet-stream]...\n",
            "Copying file://./cardd_tfrecords_all_sets/train-00015-of-00016.tfrecord [Content-Type=application/octet-stream]...\n",
            "Copying file://./cardd_tfrecords_all_sets/train-00008-of-00016.tfrecord [Content-Type=application/octet-stream]...\n",
            "Copying file://./cardd_tfrecords_all_sets/val-00004-of-00008.tfrecord [Content-Type=application/octet-stream]...\n",
            "Copying file://./cardd_tfrecords_all_sets/train-00009-of-00016.tfrecord [Content-Type=application/octet-stream]...\n",
            "Copying file://./cardd_tfrecords_all_sets/test-00000-of-00004.tfrecord [Content-Type=application/octet-stream]...\n",
            "Copying file://./cardd_tfrecords_all_sets/train-00000-of-00016.tfrecord [Content-Type=application/octet-stream]...\n",
            "Copying file://./cardd_tfrecords_all_sets/val-00003-of-00008.tfrecord [Content-Type=application/octet-stream]...\n",
            "Copying file://./cardd_tfrecords_all_sets/val-00005-of-00008.tfrecord [Content-Type=application/octet-stream]...\n",
            "Copying file://./cardd_tfrecords_all_sets/train-00012-of-00016.tfrecord [Content-Type=application/octet-stream]...\n",
            "Copying file://./cardd_tfrecords_all_sets/val-00007-of-00008.tfrecord [Content-Type=application/octet-stream]...\n",
            "Copying file://./cardd_tfrecords_all_sets/val-00002-of-00008.tfrecord [Content-Type=application/octet-stream]...\n",
            "Copying file://./cardd_tfrecords_all_sets/train-00010-of-00016.tfrecord [Content-Type=application/octet-stream]...\n",
            "Copying file://./cardd_tfrecords_all_sets/train-00001-of-00016.tfrecord [Content-Type=application/octet-stream]...\n",
            "Copying file://./cardd_tfrecords_all_sets/train-00011-of-00016.tfrecord [Content-Type=application/octet-stream]...\n",
            "Copying file://./cardd_tfrecords_all_sets/train-00007-of-00016.tfrecord [Content-Type=application/octet-stream]...\n",
            "Copying file://./cardd_tfrecords_all_sets/val-00000-of-00008.tfrecord [Content-Type=application/octet-stream]...\n",
            "Copying file://./cardd_tfrecords_all_sets/test-00001-of-00004.tfrecord [Content-Type=application/octet-stream]...\n",
            "Copying file://./cardd_tfrecords_all_sets/train-00004-of-00016.tfrecord [Content-Type=application/octet-stream]...\n",
            "Copying file://./cardd_tfrecords_all_sets/test-00003-of-00004.tfrecord [Content-Type=application/octet-stream]...\n",
            "Copying file://./cardd_tfrecords_all_sets/test-00002-of-00004.tfrecord [Content-Type=application/octet-stream]...\n",
            "Copying file://./cardd_tfrecords_all_sets/val-00006-of-00008.tfrecord [Content-Type=application/octet-stream]...\n",
            "Copying file://./cardd_tfrecords_all_sets/train-00002-of-00016.tfrecord [Content-Type=application/octet-stream]...\n",
            "|\n",
            "==> NOTE: You are performing a sequence of gsutil operations that may\n",
            "run significantly faster if you instead use gsutil -m cp ... Please\n",
            "see the -m section under \"gsutil help options\" for further information\n",
            "about when gsutil -m can be advantageous.\n",
            "\n",
            "\n",
            "Operation completed over 28 objects/2.8 GiB.                                     \n"
          ]
        }
      ],
      "source": [
        "!gsutil cp -r './cardd_tfrecords_all_sets' gs://car-damage-recognition"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}